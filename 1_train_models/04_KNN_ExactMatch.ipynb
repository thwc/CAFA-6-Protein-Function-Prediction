{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a004dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ÄÃ£ cáº¥u hÃ¬nh ROOT: E:\\CAFA-6-Protein-Function-Prediction\n",
      "ðŸ“‚ Input: E:\\CAFA-6-Protein-Function-Prediction\\input\n",
      "ðŸ“‚ Output: E:\\CAFA-6-Protein-Function-Prediction\\output\n",
      "ðŸ“‚ Models: E:\\CAFA-6-Protein-Function-Prediction\\models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- 1. Cáº¤U HÃŒNH Gá»C (ROOT) ---\n",
    "# DÃ¹ng r'' Ä‘á»ƒ Python hiá»ƒu Ä‘Ã¢y lÃ  Ä‘Æ°á»ng dáº«n Windows (khÃ´ng bá»‹ lá»—i kÃ½ tá»± Ä‘áº·c biá»‡t)\n",
    "ROOT = r'E:\\CAFA-6-Protein-Function-Prediction'\n",
    "\n",
    "# --- 2. Äá»ŠNH NGHÄ¨A CÃC THÆ¯ Má»¤C CON (Tá»± Ä‘á»™ng ná»‘i Ä‘uÃ´i) ---\n",
    "# os.path.join giÃºp ná»‘i Ä‘Æ°á»ng dáº«n Ä‘Ãºng chuáº©n cho cáº£ Windows/Linux/Mac\n",
    "INPUT_DIR  = os.path.join(ROOT, 'input')\n",
    "OUTPUT_DIR = os.path.join(ROOT, 'output')\n",
    "MODEL_DIR  = os.path.join(ROOT, 'models')\n",
    "\n",
    "# Táº¡o sáºµn thÆ° má»¥c output vÃ  models náº¿u chÆ°a cÃ³ (TrÃ¡nh lá»—i khÃ´ng lÆ°u Ä‘Æ°á»£c file)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"âœ… ÄÃ£ cáº¥u hÃ¬nh ROOT: {ROOT}\")\n",
    "print(f\"ðŸ“‚ Input: {INPUT_DIR}\")\n",
    "print(f\"ðŸ“‚ Output: {OUTPUT_DIR}\")\n",
    "print(f\"ðŸ“‚ Models: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad70bee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n",
      "\n",
      ">>> 1. Running Exact Sequence Matching (Lookup)...\n",
      "   Indexing Train Sequences...\n",
      "   Loading Train Terms...\n",
      "   Matching Test Sequences...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9dc24f3a2846cdb70d84f112e1ade7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Exact Matching: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >>> FOUND 84562 EXACT MATCHES!\n",
      ">>> Saving Exact Match to E:\\CAFA-6-Protein-Function-Prediction\\output\\submission_exact.tsv...\n",
      "\n",
      ">>> 2. Running Weighted KNN (Streaming Mode)...\n",
      "   Loading embeddings...\n",
      "   Loading ID mapping...\n",
      "   Writing results directly to E:\\CAFA-6-Protein-Function-Prediction\\output\\submission_knn.tsv...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2d950ec338432098ca7450df49d931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KNN Computing:   0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   KNN Done!\n",
      "\n",
      "SUCCESS! Generated 2 files:\n",
      "1. E:\\CAFA-6-Protein-Function-Prediction\\output\\submission_exact.tsv\n",
      "2. E:\\CAFA-6-Protein-Function-Prediction\\output\\submission_knn.tsv\n",
      "Now proceed to Notebook 05 to ensemble these files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# Cáº¤U HÃŒNH\n",
    "# ==========================================\n",
    "class Config:\n",
    "    RAW_DATA_DIR = os.path.join(INPUT_DIR, 'cafa-6-protein-function-prediction')\n",
    "    EMBED_DIR = os.path.join(INPUT_DIR, 'cafa-6-t5-embeddings')\n",
    "    \n",
    "    # File Output\n",
    "    KNN_OUTPUT = os.path.join(OUTPUT_DIR, 'submission_knn.tsv')\n",
    "    EXACT_OUTPUT = os.path.join(OUTPUT_DIR, 'submission_exact.tsv')\n",
    "\n",
    "    TRAIN_SEQ = os.path.join(RAW_DATA_DIR, 'Train', 'train_sequences.fasta')\n",
    "    TRAIN_TERMS = os.path.join(RAW_DATA_DIR, 'Train', 'train_terms.tsv')\n",
    "    TEST_SEQ = os.path.join(RAW_DATA_DIR, 'Test', 'testsuperset.fasta')\n",
    "    \n",
    "    TRAIN_EMBEDS = os.path.join(EMBED_DIR, 'train_embeds.npy')\n",
    "    TEST_EMBEDS = os.path.join(EMBED_DIR, 'test_embeds.npy')\n",
    "    \n",
    "    # Params\n",
    "    MIN_SCORE = 0.01    # Chá»‰ lÆ°u cÃ¡c Ä‘iá»ƒm > 0.01 Ä‘á»ƒ giáº£m dung lÆ°á»£ng file\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cfg = Config()\n",
    "print(f\"Running on: {cfg.DEVICE}\")\n",
    "\n",
    "# ==========================================\n",
    "# MODULE 1: EXACT MATCH LOOKUP\n",
    "# ==========================================\n",
    "def run_exact_match():\n",
    "    print(\"\\n>>> 1. Running Exact Sequence Matching (Lookup)...\")\n",
    "    \n",
    "    # 1. Load Train Sequences\n",
    "    print(\"   Indexing Train Sequences...\")\n",
    "    train_seq_map = {}\n",
    "    # DÃ¹ng try-except Ä‘á»ƒ trÃ¡nh lá»—i náº¿u file khÃ´ng tá»“n táº¡i (cho debug)\n",
    "    if not os.path.exists(cfg.TRAIN_SEQ):\n",
    "        print(f\"Error: Not found {cfg.TRAIN_SEQ}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for record in SeqIO.parse(cfg.TRAIN_SEQ, \"fasta\"):\n",
    "        seq_str = str(record.seq)\n",
    "        if '|' in record.id:\n",
    "            pid = record.id.split('|')[1]\n",
    "        else:\n",
    "            pid = record.id\n",
    "        if seq_str not in train_seq_map:\n",
    "            train_seq_map[seq_str] = []\n",
    "        train_seq_map[seq_str].append(pid)\n",
    "        \n",
    "    # 2. Load Train Terms\n",
    "    print(\"   Loading Train Terms...\")\n",
    "    df_terms = pd.read_csv(cfg.TRAIN_TERMS, sep='\\t', names=['id', 'term', 'aspect'])\n",
    "    df_terms['id'] = df_terms['id'].astype(str).str.strip()\n",
    "    \n",
    "    # Láº¥y Top 5000 terms phá»• biáº¿n nháº¥t Ä‘á»ƒ lookup cho nhanh\n",
    "    top_terms = set(df_terms['term'].value_counts().head(5000).index)\n",
    "    df_terms = df_terms[df_terms['term'].isin(top_terms)]\n",
    "    \n",
    "    id_to_terms = df_terms.groupby('id')['term'].apply(set).to_dict()\n",
    "    \n",
    "    # 3. Match Test Sequences\n",
    "    print(\"   Matching Test Sequences...\")\n",
    "    exact_matches = []\n",
    "    match_count = 0\n",
    "    \n",
    "    for record in tqdm(SeqIO.parse(cfg.TEST_SEQ, \"fasta\"), desc=\"Exact Matching\"):\n",
    "        test_seq = str(record.seq)\n",
    "        if '|' in record.id:\n",
    "            test_id = record.id.split('|')[1]\n",
    "        else:\n",
    "            test_id = record.id\n",
    "        \n",
    "        if test_seq in train_seq_map:\n",
    "            train_ids = train_seq_map[test_seq]\n",
    "            collected_terms = set()\n",
    "            for tid in train_ids:\n",
    "                if tid in id_to_terms:\n",
    "                    collected_terms.update(id_to_terms[tid])\n",
    "            \n",
    "            if collected_terms:\n",
    "                match_count += 1\n",
    "                for term in collected_terms:\n",
    "                    # GÃ¡n Ä‘iá»ƒm 0.99 (gáº§n tuyá»‡t Ä‘á»‘i)\n",
    "                    exact_matches.append({'id': test_id, 'term': term, 'exact_score': 0.99})\n",
    "                \n",
    "    print(f\"   >>> FOUND {match_count} EXACT MATCHES!\")\n",
    "    return pd.DataFrame(exact_matches)\n",
    "\n",
    "# ==========================================\n",
    "# MODULE 2: WEIGHTED KNN (MEMORY OPTIMIZED)\n",
    "# ==========================================\n",
    "def run_knn():\n",
    "    print(\"\\n>>> 2. Running Weighted KNN (Streaming Mode)...\")\n",
    "    \n",
    "    # Load Data\n",
    "    print(\"   Loading embeddings...\")\n",
    "    X_train = np.load(cfg.TRAIN_EMBEDS)\n",
    "    X_test = np.load(cfg.TEST_EMBEDS)\n",
    "    \n",
    "    # Chuyá»ƒn sang Torch & Normalize\n",
    "    X_train = torch.from_numpy(X_train).to(cfg.DEVICE)\n",
    "    X_train = torch.nn.functional.normalize(X_train, p=2, dim=1)\n",
    "    \n",
    "    X_test = torch.from_numpy(X_test) # ChÆ°a Ä‘áº©y lÃªn GPU vá»™i\n",
    "    X_test = torch.nn.functional.normalize(X_test, p=2, dim=1)\n",
    "    \n",
    "    # Load Labels Map\n",
    "    print(\"   Loading ID mapping...\")\n",
    "    df = pd.read_csv(cfg.TRAIN_TERMS, sep='\\t', names=['id', 'term', 'aspect'])\n",
    "    \n",
    "    # Load Train IDs\n",
    "    train_ids_npy = np.load(os.path.join(cfg.EMBED_DIR, 'train_ids.npy'))\n",
    "    train_ids_npy = [str(x).split('|')[1] if '|' in str(x) else str(x) for x in train_ids_npy]\n",
    "    \n",
    "    # Táº¡o Map: Index -> List of Terms\n",
    "    id_to_terms = df.groupby('id')['term'].apply(list).to_dict()\n",
    "    idx_to_terms = {}\n",
    "    for i, pid in enumerate(train_ids_npy):\n",
    "        if pid in id_to_terms:\n",
    "            idx_to_terms[i] = id_to_terms[pid]\n",
    "            \n",
    "    # Load Test IDs\n",
    "    test_ids_npy = np.load(os.path.join(cfg.EMBED_DIR, 'test_ids.npy'))\n",
    "    test_ids_npy = [str(x).split('|')[1] if '|' in str(x) else str(x) for x in test_ids_npy]\n",
    "    \n",
    "    # Config KNN\n",
    "    K = 10\n",
    "    BATCH_SIZE = 500 # Giá»¯ batch nhá» Ä‘á»ƒ tiáº¿t kiá»‡m VRAM\n",
    "    num_test = len(test_ids_npy)\n",
    "    \n",
    "    print(f\"   Writing results directly to {cfg.KNN_OUTPUT}...\")\n",
    "    \n",
    "    # --- [Sá»¬A Lá»–I LOGIC QUAN TRá»ŒNG á»ž ÄÃ‚Y] ---\n",
    "    # Má»Ÿ file TRÆ¯á»šC, sau Ä‘Ã³ loop tÃ­nh toÃ¡n BÃŠN TRONG\n",
    "    with open(cfg.KNN_OUTPUT, 'w') as f:\n",
    "        # Header (Optional, nhÆ°ng thÆ°á»ng submission khÃ´ng cáº§n header)\n",
    "        # f.write(\"ProteinID\\tGO_ID\\tScore\\n\") \n",
    "        \n",
    "        for i in tqdm(range(0, num_test, BATCH_SIZE), desc=\"KNN Computing\"):\n",
    "            # 1. Láº¥y batch test & Ä‘áº©y lÃªn GPU\n",
    "            batch_test = X_test[i : i + BATCH_SIZE].to(cfg.DEVICE)\n",
    "            \n",
    "            # 2. TÃ­nh Cosine Similarity (Matrix Multiplication)\n",
    "            sim_matrix = torch.mm(batch_test, X_train.t())\n",
    "            \n",
    "            # 3. Láº¥y Top K\n",
    "            vals, inds = torch.topk(sim_matrix, k=K, dim=1)\n",
    "            vals = vals.cpu().numpy()\n",
    "            inds = inds.cpu().numpy()\n",
    "            \n",
    "            # 4. Xá»­ lÃ½ tá»«ng protein trong batch\n",
    "            for j in range(len(batch_test)):\n",
    "                tid = test_ids_npy[i + j]\n",
    "                scores = {}\n",
    "                total_weight = 0\n",
    "                \n",
    "                # Cá»™ng dá»“n Ä‘iá»ƒm tá»« K hÃ ng xÃ³m\n",
    "                for k in range(K):\n",
    "                    idx = inds[j, k]\n",
    "                    sim = vals[j, k]\n",
    "                    \n",
    "                    if sim > 0.3: # Chá»‰ xÃ©t hÃ ng xÃ³m cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng > 0.3\n",
    "                        weight = sim * sim\n",
    "                        total_weight += weight\n",
    "                        if idx in idx_to_terms:\n",
    "                            for term in idx_to_terms[idx]:\n",
    "                                scores[term] = scores.get(term, 0) + weight\n",
    "                                \n",
    "                # Chuáº©n hÃ³a Ä‘iá»ƒm sá»‘\n",
    "                if total_weight > 0:\n",
    "                    for term in scores:\n",
    "                        scores[term] /= total_weight\n",
    "                        scores[term] *= min(1.0, total_weight)\n",
    "                \n",
    "                # 5. GHI FILE NGAY Láº¬P Tá»¨C (Streaming)\n",
    "                for term, score in scores.items():\n",
    "                    if score > cfg.MIN_SCORE:\n",
    "                        f.write(f\"{tid}\\t{term}\\t{score:.3f}\\n\")\n",
    "                        \n",
    "            # Giáº£i phÃ³ng VRAM sau má»—i batch\n",
    "            del batch_test, sim_matrix, vals, inds\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Dá»n dáº¹p cuá»‘i cÃ¹ng\n",
    "    del X_train, X_test\n",
    "    gc.collect()\n",
    "    print(\"   KNN Done!\")\n",
    "\n",
    "# ==========================================\n",
    "# MAIN EXECUTION\n",
    "# ==========================================\n",
    "def main():\n",
    "    # 1. Cháº¡y Exact Match\n",
    "    df_exact = run_exact_match()\n",
    "    print(f\">>> Saving Exact Match to {cfg.EXACT_OUTPUT}...\")\n",
    "    if not df_exact.empty:\n",
    "        df_exact[['id', 'term', 'exact_score']].to_csv(cfg.EXACT_OUTPUT, sep='\\t', index=False, header=False)\n",
    "    else:\n",
    "        print(\"Warning: No exact matches found. File will be empty.\")\n",
    "        # Táº¡o file rá»—ng Ä‘á»ƒ Notebook 05 khÃ´ng bá»‹ lá»—i file not found\n",
    "        open(cfg.EXACT_OUTPUT, 'w').close() \n",
    "    \n",
    "    # 2. Cháº¡y KNN (HÃ m nÃ y Ä‘Ã£ tá»± save file submission_knn.tsv)\n",
    "    run_knn()\n",
    "    \n",
    "    print(\"\\nSUCCESS! Generated 2 files:\")\n",
    "    print(f\"1. {cfg.EXACT_OUTPUT}\")\n",
    "    print(f\"2. {cfg.KNN_OUTPUT}\")\n",
    "    print(\"Now proceed to Notebook 05 to ensemble these files.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
